{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8af367a4-67f2-4fcd-a1b1-502b8fb19ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter('ignore', pd.errors.SettingWithCopyWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1910d93f-ee03-481c-af08-cc1cb9c81bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wOrdinal = pd.read_csv('~/Documents/AmesHousingML/clean_data_ordinal.csv') \n",
    "train_originalCleaned = pd.read_csv('~/Documents/AmesHousingML/clean_data_original.csv') \n",
    "train_wOnlyDummies = pd.read_csv('~/Documents/AmesHousingML/clean_data_dummified.csv') \n",
    "train_wOnlyDummiesNoDrop = pd.read_csv('~/Documents/AmesHousingML/clean_data_dummified_noDrop.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acf258a5-dec5-42cd-9881-60cb09d7dd72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2576, 86)\n",
      "(2576, 266)\n",
      "(2576, 86)\n",
      "(2576, 85)\n",
      "(2576, 265)\n",
      "(2576, 85)\n"
     ]
    }
   ],
   "source": [
    "print(train_originalCleaned.shape)\n",
    "print(train_wOnlyDummies.shape)\n",
    "print(train_wOrdinal.shape)\n",
    "\n",
    "train_originalCleaned=train_originalCleaned.drop('PID', axis=1)\n",
    "train_wOnlyDummies=train_wOnlyDummies.drop('PID', axis=1)\n",
    "train_wOrdinal=train_wOrdinal.drop('PID', axis=1)\n",
    "\n",
    "print(train_originalCleaned.shape)\n",
    "print(train_wOnlyDummies.shape)\n",
    "print(train_wOrdinal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bf75f6-9ac0-4e46-9b95-fa6f1341da48",
   "metadata": {},
   "source": [
    "## Finding & Dealing with Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1930a518-503a-4bac-a04c-50934bb1dcdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outlier_threshold = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d78fe0f9-6003-4b6b-a380-e766ff20247a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q1 = train_wOrdinal['SalePrice'].quantile(.25)\n",
    "Q3 = train_wOrdinal['SalePrice'].quantile(.75)\n",
    "IQR = Q3 - Q1\n",
    "new_bounds = Q3 + outlier_threshold * IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f57ef26-9af8-463e-bfce-66c0d02075e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "before_outlier_total = train_wOrdinal.count()[1]\n",
    "train_wOrdinal.drop(train_wOrdinal[train_wOrdinal['SalePrice'] > new_bounds].index, axis=0, inplace = True)\n",
    "post_outlier_total = train_wOrdinal.count()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92c4ebe9-18f1-4564-a478-87a00cae506a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_outlier_total - post_outlier_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "876b6d95-2aba-4f4a-be14-4d23d2b98f35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q1 = train_originalCleaned['SalePrice'].quantile(.25)\n",
    "Q3 = train_originalCleaned['SalePrice'].quantile(.75)\n",
    "IQR = Q3 - Q1\n",
    "new_bounds = Q3 + outlier_threshold * IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad6c3a22-8600-4570-b695-e7336fc5a8f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "before_outlier_total = train_originalCleaned.count()[1]\n",
    "train_originalCleaned.drop(train_originalCleaned[train_originalCleaned['SalePrice'] > new_bounds].index, axis=0, inplace = True)\n",
    "post_outlier_total = train_originalCleaned.count()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af714fe1-2560-4687-a79b-686600dbcf91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_outlier_total - post_outlier_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90ca370c-ee92-4125-a357-53977ff3386b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q1 = train_wOnlyDummies['SalePrice'].quantile(.25)\n",
    "Q3 = train_wOnlyDummies['SalePrice'].quantile(.75)\n",
    "IQR = Q3 - Q1\n",
    "new_bounds = Q3 + outlier_threshold * IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6430cc76-d1b9-42e1-aad4-078ddf5d76a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "before_outlier_total = train_wOnlyDummies.count()[1]\n",
    "train_wOnlyDummies.drop(train_wOnlyDummies[train_wOnlyDummies['SalePrice'] > new_bounds].index, axis=0, inplace = True)\n",
    "post_outlier_total = train_wOnlyDummies.count()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5796e25e-e140-4354-9d73-8d5becb45923",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_outlier_total - post_outlier_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dac38dc-c2a1-4699-b145-84fe9fdcc9e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q1 = train_wOnlyDummiesNoDrop['SalePrice'].quantile(.25)\n",
    "Q3 = train_wOnlyDummiesNoDrop['SalePrice'].quantile(.75)\n",
    "IQR = Q3 - Q1\n",
    "new_bounds = Q3 + outlier_threshold * IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53aa6a15-960b-461a-941e-1e4c1ceeca73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "before_outlier_total = train_wOnlyDummiesNoDrop.count()[1]\n",
    "train_wOnlyDummiesNoDrop.drop(train_wOnlyDummiesNoDrop[train_wOnlyDummiesNoDrop['SalePrice'] > new_bounds].index, axis=0, inplace = True)\n",
    "post_outlier_total = train_wOnlyDummiesNoDrop.count()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ac98246-fa3b-484f-9e3b-1eae9ad5d80d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_outlier_total - post_outlier_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8254fa67-8f73-4ff5-80aa-d5adafff7bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "masterScores = pd.DataFrame(columns = ['Model', 'r2_5kf_mean', 'rmse_5kf_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8251f028-3cf7-421f-97cd-87ccfb9a0902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ourFrames = [train_wOrdinal, train_wOnlyDummies, train_wOnlyDummiesNoDrop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d935d46a-703c-4fd0-bb46-7e7c5d0a32fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for frame in ourFrames:\n",
    "    #the features will be X (independent variables)\n",
    "    X = frame.drop('SalePrice', axis=1)\n",
    "    X_array = X.values\n",
    "    #the target (dependent variable) will be y\n",
    "    y = frame['SalePrice']\n",
    "    y_array = y.values\n",
    "\n",
    "    #Split your training and testing sets of data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    \n",
    "    params = {\n",
    "                'objective': 'regression',  # for regression tasks\n",
    "                'metric': 'mse',\n",
    "                'boosting_type': 'gbdt',\n",
    "                'n_estimators': 100,  # Number of boosting stages\n",
    "                'learning_rate': 0.05,\n",
    "                'max_depth': 6,\n",
    "                # Add other hyperparameters as needed\n",
    "            }\n",
    "\n",
    "    # Create a XGBoost Model\n",
    "    lgb_model = lgb.LGBMRegressor(**params, random_state=42)\n",
    "                        \n",
    "    # Train the model on the training set\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    lgb_model_y_pred = lgb_model.predict(X_test)\n",
    "\n",
    "    # Evaluate the Random Forest model\n",
    "    lgb_model_r2 = r2_score(y_test, lgb_model_y_pred)\n",
    "    print(f'R-squared on the test set: {lgb_model_r2}')\n",
    "\n",
    "    lgb_model_mse = mean_squared_error(y_test, lgb_model_y_pred)\n",
    "    print(f'Mean Squared Error on the test set: {lgb_model_mse}')\n",
    "\n",
    "    # Root Mean Squared Error (RMSE) on the test set\n",
    "    lgb_model_rmse = mean_squared_error(y_test, lgb_model_y_pred, squared=False)\n",
    "    print(\"Root Mean Squared Error (RMSE) on the test set:\", lgb_model_rmse)\n",
    "\n",
    "    # Display feature importances\n",
    "    feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': lgb_model.feature_importances_})\n",
    "    feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "    print('\\nFeature Importances:')\n",
    "    print(feature_importances)\n",
    "    \n",
    "    \n",
    "    # Create a KFold object\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(lgb_model, X, y, cv=kf, scoring='r2')\n",
    "    # You can replace 'r2' with other scoring metrics like 'neg_mean_squared_error', etc.\n",
    "\n",
    "    # Display the cross-validation scores\n",
    "    print(\"Cross-Validation Scores:\", cv_scores, '\\n')\n",
    "\n",
    "    # Print the mean and standard deviation of the scores\n",
    "    print(f\"Mean R^2: {cv_scores.mean()}\", '\\n')\n",
    "    print(f\"Standard Deviation R^2: {cv_scores.std()}\")\n",
    "    \n",
    "        \n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    \n",
    "    # feat_importances = pd.Series(rf_model.feature_importances_, index=X.columns)\n",
    "    # feat_importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "522aab62-9f76-4799-85f1-7221584a0a57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>TotalHouseSF</th>\n",
       "      <th>TotalBathroomCount</th>\n",
       "      <th>QualityOutdoorSF</th>\n",
       "      <th>YearAndRemodAvg</th>\n",
       "      <th>NonHouseSF</th>\n",
       "      <th>HighQualFinSF</th>\n",
       "      <th>HouseLotRatio</th>\n",
       "      <th>FrontageLotRatio</th>\n",
       "      <th>QualityOutdoorLotRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>126000</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1939</td>\n",
       "      <td>1950</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>238.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>618.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>856</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1712.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>166</td>\n",
       "      <td>1944.5</td>\n",
       "      <td>-6178.0</td>\n",
       "      <td>1712.0</td>\n",
       "      <td>21.698352</td>\n",
       "      <td>0.760456</td>\n",
       "      <td>2.103929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1049</td>\n",
       "      <td>139500</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1984</td>\n",
       "      <td>1984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>149.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>552.0</td>\n",
       "      <td>2</td>\n",
       "      <td>393.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2098.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>105</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>-2137.0</td>\n",
       "      <td>2098.0</td>\n",
       "      <td>49.539551</td>\n",
       "      <td>0.991736</td>\n",
       "      <td>2.479339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>124900</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6060</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1930</td>\n",
       "      <td>2007</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>737.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2007</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1838.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>282</td>\n",
       "      <td>1968.5</td>\n",
       "      <td>-4222.0</td>\n",
       "      <td>1838.0</td>\n",
       "      <td>30.330033</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>4.653465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1039</td>\n",
       "      <td>114000</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8146</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1900</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>717</td>\n",
       "      <td>322</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>279</td>\n",
       "      <td>1951.5</td>\n",
       "      <td>-6702.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>17.726492</td>\n",
       "      <td>0.982077</td>\n",
       "      <td>3.424994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>227000</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>8400</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2001</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>643.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>810</td>\n",
       "      <td>855</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2475.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>45</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>-5925.0</td>\n",
       "      <td>2475.0</td>\n",
       "      <td>29.464286</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GrLivArea  SalePrice  MSSubClass  MSZoning  LotFrontage  LotArea  Street  \\\n",
       "0        856     126000          30         5         60.0     7890       1   \n",
       "1       1049     139500         120         5         42.0     4235       1   \n",
       "2       1001     124900          30         1         60.0     6060       1   \n",
       "3       1039     114000          70         5         80.0     8146       1   \n",
       "4       1665     227000          60         5         70.0     8400       1   \n",
       "\n",
       "   Alley  LotShape  LandContour  Utilities  LotConfig  LandSlope  \\\n",
       "0      1         3            3          0          0          0   \n",
       "1      1         3            3          0          4          0   \n",
       "2      1         3            3          0          4          0   \n",
       "3      1         3            3          0          0          0   \n",
       "4      1         3            3          0          4          0   \n",
       "\n",
       "   Neighborhood  Condition1  Condition2  BldgType  HouseStyle  OverallQual  \\\n",
       "0            19           2           2         0           2            6   \n",
       "1             7           2           2         4           2            5   \n",
       "2            10           2           2         0           2            5   \n",
       "3            18           2           2         0           5            4   \n",
       "4            15           2           2         0           5            8   \n",
       "\n",
       "   OverallCond  YearBuilt  YearRemodAdd  RoofStyle  RoofMatl  Exterior1st  \\\n",
       "0            6       1939          1950          1         0           13   \n",
       "1            5       1984          1984          1         0            6   \n",
       "2            9       1930          2007          3         0            8   \n",
       "3            8       1900          2003          1         0            8   \n",
       "4            6       2001          2001          1         0           12   \n",
       "\n",
       "   Exterior2nd  MasVnrType  MasVnrArea  ExterQual  ExterCond  Foundation  \\\n",
       "0           14           2         0.0          3          3           1   \n",
       "1            6           1       149.0          4          3           1   \n",
       "2            8           2         0.0          4          3           0   \n",
       "3            8           2         0.0          4          4           0   \n",
       "4           13           2         0.0          4          3           2   \n",
       "\n",
       "   BsmtQual  BsmtCond  BsmtExposure  BsmtFinType1  BsmtFinSF1  BsmtFinType2  \\\n",
       "0         4         4             2             3       238.0             1   \n",
       "1         5         4             3             3       552.0             2   \n",
       "2         4         4             2             2       737.0             1   \n",
       "3         3         4             2             1         0.0             1   \n",
       "4         5         4             2             3       643.0             1   \n",
       "\n",
       "   BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  Heating  HeatingQC  CentralAir  \\\n",
       "0         0.0      618.0        856.0        1          3           1   \n",
       "1       393.0      104.0       1049.0        1          3           1   \n",
       "2         0.0      100.0        837.0        1          5           1   \n",
       "3         0.0      405.0        405.0        1          4           1   \n",
       "4         0.0      167.0        810.0        1          5           1   \n",
       "\n",
       "   Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  BsmtFullBath  BsmtHalfBath  \\\n",
       "0           3       856         0             0           1.0           0.0   \n",
       "1           3      1049         0             0           1.0           0.0   \n",
       "2           3      1001         0             0           0.0           0.0   \n",
       "3           3       717       322             0           0.0           0.0   \n",
       "4           3       810       855             0           1.0           0.0   \n",
       "\n",
       "   FullBath  HalfBath  BedroomAbvGr  KitchenAbvGr  KitchenQual  TotRmsAbvGrd  \\\n",
       "0         1         0             2             1            3             4   \n",
       "1         2         0             2             1            4             5   \n",
       "2         1         0             2             1            4             5   \n",
       "3         1         0             2             1            3             6   \n",
       "4         2         1             3             1            4             6   \n",
       "\n",
       "   Functional  Fireplaces  FireplaceQu  GarageType  GarageYrBlt  GarageFinish  \\\n",
       "0           6           1            5           5       1939.0             1   \n",
       "1           6           0            1           1       1984.0             3   \n",
       "2           6           0            1           5       1930.0             1   \n",
       "3           6           0            1           5       1940.0             1   \n",
       "4           6           0            1           1       2001.0             3   \n",
       "\n",
       "   GarageCars  GarageArea  GarageQual  GarageCond  PavedDrive  WoodDeckSF  \\\n",
       "0         2.0       399.0           4           4           2           0   \n",
       "1         1.0       266.0           4           4           2           0   \n",
       "2         1.0       216.0           4           2           0         154   \n",
       "3         1.0       281.0           4           4           0           0   \n",
       "4         2.0       528.0           4           4           2           0   \n",
       "\n",
       "   OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  Fence  MoSold  YrSold  \\\n",
       "0            0              0          0          166      1       3    2010   \n",
       "1          105              0          0            0      1       2    2009   \n",
       "2            0             42         86            0      1      11    2007   \n",
       "3            0            168          0          111      1       5    2009   \n",
       "4           45              0          0            0      1      11    2009   \n",
       "\n",
       "   SaleType  SaleCondition  TotalHouseSF  TotalBathroomCount  \\\n",
       "0         9              4        1712.0                 2.0   \n",
       "1         9              4        2098.0                 3.0   \n",
       "2         9              4        1838.0                 1.0   \n",
       "3         9              4        1444.0                 1.0   \n",
       "4         9              4        2475.0                 3.5   \n",
       "\n",
       "   QualityOutdoorSF  YearAndRemodAvg  NonHouseSF  HighQualFinSF  \\\n",
       "0               166           1944.5     -6178.0         1712.0   \n",
       "1               105           1984.0     -2137.0         2098.0   \n",
       "2               282           1968.5     -4222.0         1838.0   \n",
       "3               279           1951.5     -6702.0         1444.0   \n",
       "4                45           2001.0     -5925.0         2475.0   \n",
       "\n",
       "   HouseLotRatio  FrontageLotRatio  QualityOutdoorLotRatio  \n",
       "0      21.698352          0.760456                2.103929  \n",
       "1      49.539551          0.991736                2.479339  \n",
       "2      30.330033          0.990099                4.653465  \n",
       "3      17.726492          0.982077                3.424994  \n",
       "4      29.464286          0.833333                0.535714  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_wOrdinal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87181a1-3d85-463b-9b9a-87fb81656074",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#name the model for our scores tracker\n",
    "model_name = 'lightgbm'\n",
    "    \n",
    "#the features will be X (independent variables)\n",
    "X = train_wOrdinal.drop('SalePrice', axis=1)\n",
    "X_array = X.values\n",
    "#the target (dependent variable) will be y\n",
    "y = train_wOrdinal['SalePrice']\n",
    "y_array = y.values\n",
    "\n",
    "#Split your training and testing sets of data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a XGBoost Model\n",
    "lgb_model = lgb.LGBMRegressor(random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "lgb_model_y_pred = lgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "lgb_model_r2 = r2_score(y_test, lgb_model_y_pred)\n",
    "print(f'R-squared on the test set: {lgb_model_r2}')\n",
    "\n",
    "lgb_model_mse = mean_squared_error(y_test, lgb_model_y_pred)\n",
    "print(f'Mean Squared Error on the test set: {lgb_model_mse}')\n",
    "\n",
    "# Root Mean Squared Error (RMSE) on the test set\n",
    "lgb_model_rmse = mean_squared_error(y_test, lgb_model_y_pred, squared=False)\n",
    "print(\"Root Mean Squared Error (RMSE) on the test set:\", lgb_model_rmse)\n",
    "\n",
    "# Display feature importances\n",
    "feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': lgb_model.feature_importances_})\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "print('\\nFeature Importances:')\n",
    "print(feature_importances)\n",
    "    \n",
    "    \n",
    "   # Create a KFold object\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(lgb_model, X, y, cv=kf, scoring='r2')\n",
    "# You can replace 'r2' with other scoring metrics like 'neg_mean_squared_error', etc.\n",
    "\n",
    "def rmse_scorer(y_true, y_pred):\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        return rmse\n",
    "    \n",
    "    \n",
    "# Define the scoring function using neg_mean_squared_error\n",
    "scorer = make_scorer(rmse_scorer)\n",
    "# Use cross_val_score with the defined scorer\n",
    "rmse_scores = cross_val_score(lgb_model, X, y, cv=kf, scoring=scorer)\n",
    "\n",
    "\n",
    "\n",
    "# Display the cross-validation scores\n",
    "print(\"Cross-Validation Scores Rsquared:\", cv_scores, '\\n')\n",
    "print(\"Cross-Validation Scores RMSE:\", rmse_scores, '\\n')\n",
    "\n",
    "# Print the mean and standard deviation of the scores\n",
    "print(f\"Mean R^2: {cv_scores.mean()}\", '\\n')\n",
    "print(f\"Standard Deviation R^2: {cv_scores.std()}\", '\\n')\n",
    "print(f\"Mean RMSE: {rmse_scores.mean()}\")\n",
    "\n",
    "record = {'Model': model_name, 'r2_5kf_mean': cv_scores.mean(), 'rmse_5kf_mean': rmse_scores.mean()}\n",
    "masterScores = masterScores.append(record, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b811b9f9-b7a8-47f8-aa23-c0eb3d8dff40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>r2_5kf_mean</th>\n",
       "      <th>rmse_5kf_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Model, r2_5kf_mean, rmse_5kf_mean]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterScores #want to use the sci kit and catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d907f91c-be68-40d1-8649-14da9b0311eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported to 'masterScores_scikitBoosting.csv' in the same working directory.\n"
     ]
    }
   ],
   "source": [
    "output_file = 'masterScores_scikitBoosting.csv'\n",
    "\n",
    "masterScores.to_csv(output_file, index=False, mode='w')\n",
    "\n",
    "print(f\"DataFrame exported to '{output_file}' in the same working directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15a19d67-6536-4367-80a0-07890a0ecbc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-29 11:16:37,982] A new study created in memory with name: no-name-0a5e8dc6-998a-49f1-8906-c6a28da9b5e3\n",
      "[I 2024-01-29 11:16:43,202] Trial 0 finished with value: 342054325.35056657 and parameters: {'n_estimators': 272, 'learning_rate': 0.06669845644454007, 'max_depth': 5}. Best is trial 0 with value: 342054325.35056657.\n",
      "[I 2024-01-29 11:16:52,498] Trial 1 finished with value: 567777465.8897405 and parameters: {'n_estimators': 270, 'learning_rate': 0.013511834801014286, 'max_depth': 10}. Best is trial 0 with value: 342054325.35056657.\n",
      "[I 2024-01-29 11:16:54,872] Trial 2 finished with value: 1095159296.4470773 and parameters: {'n_estimators': 86, 'learning_rate': 0.012736252020899938, 'max_depth': 8}. Best is trial 0 with value: 342054325.35056657.\n",
      "[I 2024-01-29 11:17:01,287] Trial 3 finished with value: 506279349.47848934 and parameters: {'n_estimators': 192, 'learning_rate': 0.09459027524835512, 'max_depth': 9}. Best is trial 0 with value: 342054325.35056657.\n",
      "[I 2024-01-29 11:17:12,267] Trial 4 finished with value: 355811965.3250263 and parameters: {'n_estimators': 498, 'learning_rate': 0.037139571363636076, 'max_depth': 6}. Best is trial 0 with value: 342054325.35056657.\n",
      "[I 2024-01-29 11:17:20,598] Trial 5 finished with value: 486048490.56006485 and parameters: {'n_estimators': 300, 'learning_rate': 0.0106931655686168, 'max_depth': 8}. Best is trial 0 with value: 342054325.35056657.\n",
      "[I 2024-01-29 11:17:23,814] Trial 6 finished with value: 315339948.2972841 and parameters: {'n_estimators': 286, 'learning_rate': 0.06883239845606107, 'max_depth': 3}. Best is trial 6 with value: 315339948.2972841.\n",
      "[I 2024-01-29 11:17:28,416] Trial 7 finished with value: 401083987.8210631 and parameters: {'n_estimators': 173, 'learning_rate': 0.06544645733367492, 'max_depth': 7}. Best is trial 6 with value: 315339948.2972841.\n",
      "[I 2024-01-29 11:17:39,433] Trial 8 finished with value: 563362488.5989321 and parameters: {'n_estimators': 308, 'learning_rate': 0.07667224873215445, 'max_depth': 10}. Best is trial 6 with value: 315339948.2972841.\n",
      "[I 2024-01-29 11:17:41,669] Trial 9 finished with value: 446976685.30639577 and parameters: {'n_estimators': 154, 'learning_rate': 0.02005789920656552, 'max_depth': 4}. Best is trial 6 with value: 315339948.2972841.\n",
      "[I 2024-01-29 11:17:46,419] Trial 10 finished with value: 316918290.9795577 and parameters: {'n_estimators': 422, 'learning_rate': 0.04677660332176764, 'max_depth': 3}. Best is trial 6 with value: 315339948.2972841.\n",
      "[I 2024-01-29 11:17:51,376] Trial 11 finished with value: 323678012.3039424 and parameters: {'n_estimators': 438, 'learning_rate': 0.044285635136806785, 'max_depth': 3}. Best is trial 6 with value: 315339948.2972841.\n",
      "[I 2024-01-29 11:17:55,757] Trial 12 finished with value: 321531607.90571725 and parameters: {'n_estimators': 388, 'learning_rate': 0.04908693066030305, 'max_depth': 3}. Best is trial 6 with value: 315339948.2972841.\n",
      "[I 2024-01-29 11:18:02,700] Trial 13 finished with value: 333667925.40329444 and parameters: {'n_estimators': 375, 'learning_rate': 0.08753315037511897, 'max_depth': 5}. Best is trial 6 with value: 315339948.2972841.\n",
      "[I 2024-01-29 11:18:08,240] Trial 14 finished with value: 317203645.0393378 and parameters: {'n_estimators': 369, 'learning_rate': 0.0320321242845135, 'max_depth': 4}. Best is trial 6 with value: 315339948.2972841.\n",
      "[I 2024-01-29 11:18:13,489] Trial 15 finished with value: 301159757.09769565 and parameters: {'n_estimators': 466, 'learning_rate': 0.059750998152862965, 'max_depth': 3}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:18:22,719] Trial 16 finished with value: 331771360.3740396 and parameters: {'n_estimators': 499, 'learning_rate': 0.06118756474629604, 'max_depth': 5}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:18:23,634] Trial 17 finished with value: 381732993.56449926 and parameters: {'n_estimators': 59, 'learning_rate': 0.07910517416928779, 'max_depth': 4}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:18:31,086] Trial 18 finished with value: 361982889.5591002 and parameters: {'n_estimators': 336, 'learning_rate': 0.05731899093882181, 'max_depth': 6}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:18:33,700] Trial 19 finished with value: 326574857.3563649 and parameters: {'n_estimators': 232, 'learning_rate': 0.07379354227973647, 'max_depth': 3}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:18:40,408] Trial 20 finished with value: 323077981.1831469 and parameters: {'n_estimators': 447, 'learning_rate': 0.09873444606928852, 'max_depth': 4}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:18:45,306] Trial 21 finished with value: 316453087.8739937 and parameters: {'n_estimators': 435, 'learning_rate': 0.04783444493171526, 'max_depth': 3}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:18:50,595] Trial 22 finished with value: 325340597.1731834 and parameters: {'n_estimators': 469, 'learning_rate': 0.029323755537927907, 'max_depth': 3}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:18:56,805] Trial 23 finished with value: 304763922.41289985 and parameters: {'n_estimators': 414, 'learning_rate': 0.050651407231983324, 'max_depth': 4}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:19:02,874] Trial 24 finished with value: 303503381.686461 and parameters: {'n_estimators': 401, 'learning_rate': 0.05514328228782249, 'max_depth': 4}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:19:10,405] Trial 25 finished with value: 332321023.1361798 and parameters: {'n_estimators': 404, 'learning_rate': 0.054760420260463724, 'max_depth': 5}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:19:15,696] Trial 26 finished with value: 313682227.95783615 and parameters: {'n_estimators': 347, 'learning_rate': 0.0385855784569024, 'max_depth': 4}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:19:26,185] Trial 27 finished with value: 355671555.42000496 and parameters: {'n_estimators': 474, 'learning_rate': 0.055304794464671785, 'max_depth': 6}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:19:31,479] Trial 28 finished with value: 322246568.2053043 and parameters: {'n_estimators': 345, 'learning_rate': 0.08524721999282013, 'max_depth': 4}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:19:39,195] Trial 29 finished with value: 329838348.30522555 and parameters: {'n_estimators': 407, 'learning_rate': 0.06522923103852117, 'max_depth': 5}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:19:51,473] Trial 30 finished with value: 399689383.2663904 and parameters: {'n_estimators': 467, 'learning_rate': 0.052750509887060024, 'max_depth': 7}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:19:56,648] Trial 31 finished with value: 319542812.2014029 and parameters: {'n_estimators': 343, 'learning_rate': 0.038372871348243055, 'max_depth': 4}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:20:03,666] Trial 32 finished with value: 337811570.50061595 and parameters: {'n_estimators': 371, 'learning_rate': 0.04117020829692063, 'max_depth': 5}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:20:08,540] Trial 33 finished with value: 317907350.52129966 and parameters: {'n_estimators': 323, 'learning_rate': 0.02882238509714392, 'max_depth': 4}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:20:13,247] Trial 34 finished with value: 340625804.0598272 and parameters: {'n_estimators': 249, 'learning_rate': 0.059865683849371444, 'max_depth': 5}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:20:19,486] Trial 35 finished with value: 327951981.3395457 and parameters: {'n_estimators': 419, 'learning_rate': 0.02071694495239281, 'max_depth': 4}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:20:29,693] Trial 36 finished with value: 355377616.10285103 and parameters: {'n_estimators': 459, 'learning_rate': 0.03507544258362802, 'max_depth': 6}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:20:34,327] Trial 37 finished with value: 310530603.0281002 and parameters: {'n_estimators': 393, 'learning_rate': 0.05045284291431285, 'max_depth': 3}. Best is trial 15 with value: 301159757.09769565.\n",
      "[I 2024-01-29 11:20:39,060] Trial 38 finished with value: 300178341.10290337 and parameters: {'n_estimators': 399, 'learning_rate': 0.07036064336509769, 'max_depth': 3}. Best is trial 38 with value: 300178341.10290337.\n",
      "[I 2024-01-29 11:20:44,724] Trial 39 finished with value: 292243809.54883265 and parameters: {'n_estimators': 489, 'learning_rate': 0.07019216227174811, 'max_depth': 3}. Best is trial 39 with value: 292243809.54883265.\n",
      "[I 2024-01-29 11:20:50,336] Trial 40 finished with value: 301930282.88881785 and parameters: {'n_estimators': 488, 'learning_rate': 0.06829412107504028, 'max_depth': 3}. Best is trial 39 with value: 292243809.54883265.\n",
      "[I 2024-01-29 11:20:55,930] Trial 41 finished with value: 290506518.8882238 and parameters: {'n_estimators': 483, 'learning_rate': 0.0715796764062729, 'max_depth': 3}. Best is trial 41 with value: 290506518.8882238.\n",
      "[I 2024-01-29 11:21:01,506] Trial 42 finished with value: 303462647.5459118 and parameters: {'n_estimators': 482, 'learning_rate': 0.07181395635957773, 'max_depth': 3}. Best is trial 41 with value: 290506518.8882238.\n",
      "[I 2024-01-29 11:21:07,267] Trial 43 finished with value: 306913291.9716715 and parameters: {'n_estimators': 492, 'learning_rate': 0.08078469148472829, 'max_depth': 3}. Best is trial 41 with value: 290506518.8882238.\n",
      "[I 2024-01-29 11:21:12,495] Trial 44 finished with value: 296636408.58657473 and parameters: {'n_estimators': 452, 'learning_rate': 0.06874454897951565, 'max_depth': 3}. Best is trial 41 with value: 290506518.8882238.\n",
      "[I 2024-01-29 11:21:28,902] Trial 45 finished with value: 499747613.96107763 and parameters: {'n_estimators': 450, 'learning_rate': 0.07320494469080155, 'max_depth': 9}. Best is trial 41 with value: 290506518.8882238.\n",
      "[I 2024-01-29 11:21:34,009] Trial 46 finished with value: 304233790.541475 and parameters: {'n_estimators': 436, 'learning_rate': 0.06413763846039586, 'max_depth': 3}. Best is trial 41 with value: 290506518.8882238.\n",
      "[I 2024-01-29 11:21:39,406] Trial 47 finished with value: 300021310.4893948 and parameters: {'n_estimators': 459, 'learning_rate': 0.08586585803611842, 'max_depth': 3}. Best is trial 41 with value: 290506518.8882238.\n",
      "[I 2024-01-29 11:21:44,421] Trial 48 finished with value: 294391974.1694323 and parameters: {'n_estimators': 432, 'learning_rate': 0.08843187902616614, 'max_depth': 3}. Best is trial 41 with value: 290506518.8882238.\n",
      "[I 2024-01-29 11:21:48,029] Trial 49 finished with value: 448832801.9881342 and parameters: {'n_estimators': 122, 'learning_rate': 0.08913986859285371, 'max_depth': 8}. Best is trial 41 with value: 290506518.8882238.\n",
      "[I 2024-01-29 11:21:53,874] Trial 50 finished with value: 296595911.54727876 and parameters: {'n_estimators': 499, 'learning_rate': 0.08115138186298503, 'max_depth': 3}. Best is trial 41 with value: 290506518.8882238.\n",
      "[I 2024-01-29 11:21:59,677] Trial 51 finished with value: 290596010.4016503 and parameters: {'n_estimators': 499, 'learning_rate': 0.09283021796537543, 'max_depth': 3}. Best is trial 41 with value: 290506518.8882238.\n",
      "[I 2024-01-29 11:22:05,668] Trial 52 finished with value: 288398481.2845269 and parameters: {'n_estimators': 492, 'learning_rate': 0.09272600358236215, 'max_depth': 3}. Best is trial 52 with value: 288398481.2845269.\n",
      "[I 2024-01-29 11:22:11,444] Trial 53 finished with value: 296679393.1623587 and parameters: {'n_estimators': 496, 'learning_rate': 0.09231592601597235, 'max_depth': 3}. Best is trial 52 with value: 288398481.2845269.\n",
      "[I 2024-01-29 11:22:18,818] Trial 54 finished with value: 329817471.58124554 and parameters: {'n_estimators': 482, 'learning_rate': 0.09668043250123094, 'max_depth': 4}. Best is trial 52 with value: 288398481.2845269.\n",
      "[I 2024-01-29 11:22:24,620] Trial 55 finished with value: 298476774.50663495 and parameters: {'n_estimators': 499, 'learning_rate': 0.08158837802921469, 'max_depth': 3}. Best is trial 52 with value: 288398481.2845269.\n",
      "[I 2024-01-29 11:22:29,853] Trial 56 finished with value: 298253722.79218733 and parameters: {'n_estimators': 435, 'learning_rate': 0.09228663955528045, 'max_depth': 3}. Best is trial 52 with value: 288398481.2845269.\n",
      "[I 2024-01-29 11:22:47,555] Trial 57 finished with value: 558387660.3769515 and parameters: {'n_estimators': 476, 'learning_rate': 0.07792967570171028, 'max_depth': 10}. Best is trial 52 with value: 288398481.2845269.\n",
      "[I 2024-01-29 11:22:50,648] Trial 58 finished with value: 319126393.68162584 and parameters: {'n_estimators': 202, 'learning_rate': 0.08351367736769852, 'max_depth': 4}. Best is trial 52 with value: 288398481.2845269.\n",
      "[I 2024-01-29 11:22:55,592] Trial 59 finished with value: 310102470.4993483 and parameters: {'n_estimators': 425, 'learning_rate': 0.07605206419411284, 'max_depth': 3}. Best is trial 52 with value: 288398481.2845269.\n",
      "[I 2024-01-29 11:23:02,918] Trial 60 finished with value: 336265717.2420742 and parameters: {'n_estimators': 478, 'learning_rate': 0.08937304542070536, 'max_depth': 4}. Best is trial 52 with value: 288398481.2845269.\n",
      "[I 2024-01-29 11:23:08,192] Trial 61 finished with value: 293701840.2633112 and parameters: {'n_estimators': 456, 'learning_rate': 0.09242244277464248, 'max_depth': 3}. Best is trial 52 with value: 288398481.2845269.\n",
      "[I 2024-01-29 11:23:14,072] Trial 62 finished with value: 289634190.67959625 and parameters: {'n_estimators': 499, 'learning_rate': 0.09408181543950421, 'max_depth': 3}. Best is trial 52 with value: 288398481.2845269.\n",
      "[I 2024-01-29 11:23:19,243] Trial 63 finished with value: 292914308.7238655 and parameters: {'n_estimators': 447, 'learning_rate': 0.09995466619338844, 'max_depth': 3}. Best is trial 52 with value: 288398481.2845269.\n",
      "[I 2024-01-29 11:23:26,111] Trial 64 finished with value: 326318385.9332654 and parameters: {'n_estimators': 447, 'learning_rate': 0.0998957236867991, 'max_depth': 4}. Best is trial 52 with value: 288398481.2845269.\n",
      "[I 2024-01-29 11:23:31,586] Trial 65 finished with value: 285533496.92473966 and parameters: {'n_estimators': 467, 'learning_rate': 0.0943746375371138, 'max_depth': 3}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:23:37,004] Trial 66 finished with value: 304783741.9843417 and parameters: {'n_estimators': 469, 'learning_rate': 0.09647347740127342, 'max_depth': 3}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:23:44,419] Trial 67 finished with value: 327411893.9433344 and parameters: {'n_estimators': 483, 'learning_rate': 0.09471069517724842, 'max_depth': 4}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:23:49,849] Trial 68 finished with value: 291593992.6907366 and parameters: {'n_estimators': 464, 'learning_rate': 0.0950140313695778, 'max_depth': 3}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:24:02,078] Trial 69 finished with value: 390303720.37461823 and parameters: {'n_estimators': 463, 'learning_rate': 0.09114519708435939, 'max_depth': 7}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:24:09,724] Trial 70 finished with value: 318218400.7525736 and parameters: {'n_estimators': 500, 'learning_rate': 0.0965983847477769, 'max_depth': 4}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:24:14,854] Trial 71 finished with value: 303501796.28428584 and parameters: {'n_estimators': 443, 'learning_rate': 0.0992161879861478, 'max_depth': 3}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:24:20,543] Trial 72 finished with value: 297626063.3615667 and parameters: {'n_estimators': 475, 'learning_rate': 0.09374724028568104, 'max_depth': 3}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:24:26,027] Trial 73 finished with value: 295363775.6467149 and parameters: {'n_estimators': 466, 'learning_rate': 0.08623425297814699, 'max_depth': 3}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:24:31,784] Trial 74 finished with value: 291027576.23780096 and parameters: {'n_estimators': 485, 'learning_rate': 0.0952847804165478, 'max_depth': 3}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:24:35,991] Trial 75 finished with value: 317106935.2288441 and parameters: {'n_estimators': 275, 'learning_rate': 0.09028107160896422, 'max_depth': 4}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:24:41,693] Trial 76 finished with value: 299570747.49103975 and parameters: {'n_estimators': 488, 'learning_rate': 0.08337178102618348, 'max_depth': 3}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:24:46,584] Trial 77 finished with value: 287610554.07873654 and parameters: {'n_estimators': 422, 'learning_rate': 0.09492954782441637, 'max_depth': 3}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:24:53,170] Trial 78 finished with value: 304765574.5906691 and parameters: {'n_estimators': 415, 'learning_rate': 0.09539162337535191, 'max_depth': 4}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:24:58,091] Trial 79 finished with value: 307637259.6489588 and parameters: {'n_estimators': 425, 'learning_rate': 0.09714084075515647, 'max_depth': 3}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:25:03,624] Trial 80 finished with value: 292565143.47386646 and parameters: {'n_estimators': 470, 'learning_rate': 0.08699503733404569, 'max_depth': 3}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:25:09,527] Trial 81 finished with value: 305907911.17783386 and parameters: {'n_estimators': 486, 'learning_rate': 0.09385911273651497, 'max_depth': 3}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:25:14,948] Trial 82 finished with value: 293405809.12533087 and parameters: {'n_estimators': 457, 'learning_rate': 0.09044793459326772, 'max_depth': 3}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:25:20,683] Trial 83 finished with value: 302729677.7986093 and parameters: {'n_estimators': 486, 'learning_rate': 0.08402951306830467, 'max_depth': 3}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:25:26,259] Trial 84 finished with value: 288809673.16230917 and parameters: {'n_estimators': 474, 'learning_rate': 0.09799301983202803, 'max_depth': 3}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:25:32,102] Trial 85 finished with value: 314397702.48872155 and parameters: {'n_estimators': 381, 'learning_rate': 0.09713154722642438, 'max_depth': 4}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:25:37,611] Trial 86 finished with value: 293765825.0050726 and parameters: {'n_estimators': 474, 'learning_rate': 0.09466351395294259, 'max_depth': 3}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:25:44,625] Trial 87 finished with value: 321078376.08353615 and parameters: {'n_estimators': 458, 'learning_rate': 0.08853347880669739, 'max_depth': 4}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:25:48,149] Trial 88 finished with value: 299499167.750279 and parameters: {'n_estimators': 304, 'learning_rate': 0.09793747664483358, 'max_depth': 3}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:26:03,571] Trial 89 finished with value: 453798339.34204376 and parameters: {'n_estimators': 500, 'learning_rate': 0.09262762032896625, 'max_depth': 8}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:26:08,911] Trial 90 finished with value: 315157234.28302187 and parameters: {'n_estimators': 436, 'learning_rate': 0.08742193977970875, 'max_depth': 3}. Best is trial 65 with value: 285533496.92473966.\n",
      "[I 2024-01-29 11:26:15,271] Trial 91 finished with value: 284567032.0809877 and parameters: {'n_estimators': 488, 'learning_rate': 0.09127662860772781, 'max_depth': 3}. Best is trial 91 with value: 284567032.0809877.\n",
      "[I 2024-01-29 11:26:21,117] Trial 92 finished with value: 299673544.7620255 and parameters: {'n_estimators': 480, 'learning_rate': 0.09512760082838172, 'max_depth': 3}. Best is trial 91 with value: 284567032.0809877.\n",
      "[I 2024-01-29 11:26:27,065] Trial 93 finished with value: 305000026.5839764 and parameters: {'n_estimators': 463, 'learning_rate': 0.09049745545894461, 'max_depth': 3}. Best is trial 91 with value: 284567032.0809877.\n",
      "[I 2024-01-29 11:26:33,037] Trial 94 finished with value: 300750003.6831489 and parameters: {'n_estimators': 494, 'learning_rate': 0.0982218440550288, 'max_depth': 3}. Best is trial 91 with value: 284567032.0809877.\n",
      "[I 2024-01-29 11:26:38,213] Trial 95 finished with value: 298137538.71212226 and parameters: {'n_estimators': 446, 'learning_rate': 0.09345676051437769, 'max_depth': 3}. Best is trial 91 with value: 284567032.0809877.\n",
      "[I 2024-01-29 11:26:54,888] Trial 96 finished with value: 506031504.67876774 and parameters: {'n_estimators': 488, 'learning_rate': 0.09096351853222012, 'max_depth': 9}. Best is trial 91 with value: 284567032.0809877.\n",
      "[I 2024-01-29 11:27:02,141] Trial 97 finished with value: 306304155.77794063 and parameters: {'n_estimators': 472, 'learning_rate': 0.09562953493975161, 'max_depth': 4}. Best is trial 91 with value: 284567032.0809877.\n",
      "[I 2024-01-29 11:27:07,384] Trial 98 finished with value: 293347817.31563586 and parameters: {'n_estimators': 452, 'learning_rate': 0.08797341223836573, 'max_depth': 3}. Best is trial 91 with value: 284567032.0809877.\n",
      "[I 2024-01-29 11:27:13,004] Trial 99 finished with value: 311968244.0743777 and parameters: {'n_estimators': 479, 'learning_rate': 0.08487215451270817, 'max_depth': 3}. Best is trial 91 with value: 284567032.0809877.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(learning_rate=0.09127662860772781, n_estimators=488,\n",
       "                          random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=0.09127662860772781, n_estimators=488,\n",
       "                          random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.09127662860772781, n_estimators=488,\n",
       "                          random_state=42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "    }\n",
    "\n",
    "    model = GradientBoostingRegressor(**params, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    return mse\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_model = GradientBoostingRegressor(**best_params, random_state=42)\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e442e8a7-3bc8-4ec6-a76b-b305d618c7a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 488, 'learning_rate': 0.09127662860772781, 'max_depth': 3}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826e1399-6458-4f8f-90b1-31ccb14542f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'n_estimators': 488, 'learning_rate': 0.09127662860772781, 'max_depth': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71d8b19e-0e9e-4c77-9133-7e0a450d7c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(learning_rate=0.09127662860772781, n_estimators=488,\n",
       "                          random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=0.09127662860772781, n_estimators=488,\n",
       "                          random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.09127662860772781, n_estimators=488,\n",
       "                          random_state=42)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa3b4c52-2d91-4b3e-b8e9-dbb16d84318c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a8b7742-1bc9-4e4e-b239-5832e8a6bb80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared on the test set: 0.9409483104181269\n",
      "Mean Squared Error on the test set: 284567032.0809877\n",
      "Cross-Validation Scores Rsquared: [0.9411351  0.91886975 0.94242416 0.92373525 0.88377326] \n",
      "\n",
      "Mean R^2: 0.921987503734219 \n",
      "\n",
      "Standard Deviation R^2: 0.02124801513060632 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'scikit_boosting_tuned'\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "best_r2 = r2_score(y_test, best_pred)\n",
    "print(f'R-squared on the test set: {best_r2}')\n",
    "\n",
    "best_model_mse = mean_squared_error(y_test, best_pred)\n",
    "print(f'Mean Squared Error on the test set: {best_model_mse}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=kf, scoring='r2')\n",
    "# You can replace 'r2' with other scoring metrics like 'neg_mean_squared_error', etc.\n",
    "\n",
    "    \n",
    "\n",
    "# Use cross_val_score with the defined scorer\n",
    "rmse_scores = cross_val_score(best_model, X, y, cv=kf, scoring=scorer)\n",
    "\n",
    "\n",
    "\n",
    "# Display the cross-validation scores\n",
    "print(\"Cross-Validation Scores Rsquared:\", cv_scores, '\\n')\n",
    "\n",
    "\n",
    "# Print the mean and standard deviation of the scores\n",
    "print(f\"Mean R^2: {cv_scores.mean()}\", '\\n')\n",
    "print(f\"Standard Deviation R^2: {cv_scores.std()}\", '\\n')\n",
    "\n",
    "record = {'Model': model_name, 'r2_5kf_mean': cv_scores.mean(), 'rmse_5kf_mean': rmse_scores.mean()}\n",
    "masterScores = masterScores.append(record, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d26c0a3-a37f-4632-b255-9261d0f3e58d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>r2_5kf_mean</th>\n",
       "      <th>rmse_5kf_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scikit_boosting</td>\n",
       "      <td>0.911004</td>\n",
       "      <td>19766.570369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scikit_boosting_tuned</td>\n",
       "      <td>0.921988</td>\n",
       "      <td>18500.377186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  r2_5kf_mean  rmse_5kf_mean\n",
       "0        scikit_boosting     0.911004   19766.570369\n",
       "1  scikit_boosting_tuned     0.921988   18500.377186"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe47f34e-6e0f-4a05-8a83-598849f8af22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported to 'masterScores_scikitBoosting.csv' in the same working directory.\n"
     ]
    }
   ],
   "source": [
    "output_file = 'masterScores_scikitBoosting.csv'\n",
    "\n",
    "masterScores.to_csv(output_file, index=False, mode='w')\n",
    "\n",
    "print(f\"DataFrame exported to '{output_file}' in the same working directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
