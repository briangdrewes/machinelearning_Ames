{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8af367a4-67f2-4fcd-a1b1-502b8fb19ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter('ignore', pd.errors.SettingWithCopyWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1910d93f-ee03-481c-af08-cc1cb9c81bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wOrdinal = pd.read_csv('~/Documents/AmesHousingML/clean_data_ordinal.csv') \n",
    "train_originalCleaned = pd.read_csv('~/Documents/AmesHousingML/clean_data_original.csv') \n",
    "train_wOnlyDummies = pd.read_csv('~/Documents/AmesHousingML/clean_data_dummified.csv') \n",
    "train_wOnlyDummiesNoDrop = pd.read_csv('~/Documents/AmesHousingML/clean_data_dummified_noDrop.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "acf258a5-dec5-42cd-9881-60cb09d7dd72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2576, 86)\n",
      "(2576, 266)\n",
      "(2576, 86)\n"
     ]
    }
   ],
   "source": [
    "print(train_originalCleaned.shape)\n",
    "print(train_wOnlyDummies.shape)\n",
    "print(train_wOrdinal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bf75f6-9ac0-4e46-9b95-fa6f1341da48",
   "metadata": {},
   "source": [
    "## Finding & Dealing with Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1930a518-503a-4bac-a04c-50934bb1dcdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outlier_threshold = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d78fe0f9-6003-4b6b-a380-e766ff20247a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q1 = train_wOrdinal['SalePrice'].quantile(.25)\n",
    "Q3 = train_wOrdinal['SalePrice'].quantile(.75)\n",
    "IQR = Q3 - Q1\n",
    "new_bounds = Q3 + outlier_threshold * IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0f57ef26-9af8-463e-bfce-66c0d02075e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "before_outlier_total = train_wOrdinal.count()[1]\n",
    "train_wOrdinal.drop(train_wOrdinal[train_wOrdinal['SalePrice'] > new_bounds].index, axis=0, inplace = True)\n",
    "post_outlier_total = train_wOrdinal.count()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "92c4ebe9-18f1-4564-a478-87a00cae506a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_outlier_total - post_outlier_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "876b6d95-2aba-4f4a-be14-4d23d2b98f35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q1 = train_originalCleaned['SalePrice'].quantile(.25)\n",
    "Q3 = train_originalCleaned['SalePrice'].quantile(.75)\n",
    "IQR = Q3 - Q1\n",
    "new_bounds = Q3 + outlier_threshold * IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ad6c3a22-8600-4570-b695-e7336fc5a8f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "before_outlier_total = train_originalCleaned.count()[1]\n",
    "train_originalCleaned.drop(train_originalCleaned[train_originalCleaned['SalePrice'] > new_bounds].index, axis=0, inplace = True)\n",
    "post_outlier_total = train_originalCleaned.count()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "af714fe1-2560-4687-a79b-686600dbcf91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_outlier_total - post_outlier_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "90ca370c-ee92-4125-a357-53977ff3386b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q1 = train_wOnlyDummies['SalePrice'].quantile(.25)\n",
    "Q3 = train_wOnlyDummies['SalePrice'].quantile(.75)\n",
    "IQR = Q3 - Q1\n",
    "new_bounds = Q3 + outlier_threshold * IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6430cc76-d1b9-42e1-aad4-078ddf5d76a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "before_outlier_total = train_wOnlyDummies.count()[1]\n",
    "train_wOnlyDummies.drop(train_wOnlyDummies[train_wOnlyDummies['SalePrice'] > new_bounds].index, axis=0, inplace = True)\n",
    "post_outlier_total = train_wOnlyDummies.count()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5796e25e-e140-4354-9d73-8d5becb45923",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_outlier_total - post_outlier_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8dac38dc-c2a1-4699-b145-84fe9fdcc9e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q1 = train_wOnlyDummiesNoDrop['SalePrice'].quantile(.25)\n",
    "Q3 = train_wOnlyDummiesNoDrop['SalePrice'].quantile(.75)\n",
    "IQR = Q3 - Q1\n",
    "new_bounds = Q3 + outlier_threshold * IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "53aa6a15-960b-461a-941e-1e4c1ceeca73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "before_outlier_total = train_wOnlyDummiesNoDrop.count()[1]\n",
    "train_wOnlyDummiesNoDrop.drop(train_wOnlyDummiesNoDrop[train_wOnlyDummiesNoDrop['SalePrice'] > new_bounds].index, axis=0, inplace = True)\n",
    "post_outlier_total = train_wOnlyDummiesNoDrop.count()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0ac98246-fa3b-484f-9e3b-1eae9ad5d80d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_outlier_total - post_outlier_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8254fa67-8f73-4ff5-80aa-d5adafff7bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "masterScores = pd.DataFrame(columns = ['Model', 'r2_5kf_mean', 'rmse_5kf_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8251f028-3cf7-421f-97cd-87ccfb9a0902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ourFrames = [train_wOrdinal, train_wOnlyDummies, train_wOnlyDummiesNoDrop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "71e55d2c-603a-4f89-a0d6-264c3f3acabd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for frame in ourFrames:\n",
    "    frame = frame.drop('PID', axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d935d46a-703c-4fd0-bb46-7e7c5d0a32fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared on the test set: 0.9166084147443928\n",
      "Mean Squared Error on the test set: 401859728.0576584\n",
      "Root Mean Squared Error (RMSE) on the test set: 20046.439286258756\n",
      "\n",
      "Feature Importances:\n",
      "          Feature  Importance\n",
      "81  HighQualFinSF    0.259688\n",
      "18    OverallQual    0.220354\n",
      "76   TotalHouseSF    0.169377\n",
      "53    KitchenQual    0.054261\n",
      "61     GarageCars    0.038327\n",
      "..            ...         ...\n",
      "46   LowQualFinSF    0.000143\n",
      "63     GarageQual    0.000079\n",
      "69      3SsnPorch    0.000018\n",
      "10      Utilities    0.000005\n",
      "15     Condition2    0.000000\n",
      "\n",
      "[85 rows x 2 columns]\n",
      "Cross-Validation Scores: [0.91660841 0.90567262 0.91737334 0.92009667 0.87917199] \n",
      "\n",
      "Mean R^2: 0.9077846041626992 \n",
      "\n",
      "Standard Deviation R^2: 0.01512965713463938\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "R-squared on the test set: 0.9159088419227526\n",
      "Mean Squared Error on the test set: 405230933.233806\n",
      "Root Mean Squared Error (RMSE) on the test set: 20130.348562153762\n",
      "\n",
      "Feature Importances:\n",
      "              Feature  Importance\n",
      "5         OverallQual    0.223960\n",
      "256      TotalHouseSF    0.163596\n",
      "261     HighQualFinSF    0.151428\n",
      "7           YearBuilt    0.027327\n",
      "164       BsmtQual_Gd    0.024261\n",
      "..                ...         ...\n",
      "156      ExterCond_Po    0.000000\n",
      "200  Electrical_FuseP    0.000000\n",
      "199  Electrical_FuseF    0.000000\n",
      "95    Condition2_RRAn    0.000000\n",
      "96    Condition2_RRNn    0.000000\n",
      "\n",
      "[265 rows x 2 columns]\n",
      "Cross-Validation Scores: [0.91590884 0.89451318 0.91920185 0.91232929 0.87915293] \n",
      "\n",
      "Mean R^2: 0.9042212207367448 \n",
      "\n",
      "Standard Deviation R^2: 0.015161963599623123\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "R-squared on the test set: 0.9163293062269484\n",
      "Mean Squared Error on the test set: 403204737.5400302\n",
      "Root Mean Squared Error (RMSE) on the test set: 20079.958604041745\n",
      "\n",
      "Feature Importances:\n",
      "                Feature  Importance\n",
      "297        TotalHouseSF    0.196362\n",
      "5           OverallQual    0.188993\n",
      "302       HighQualFinSF    0.132685\n",
      "121      RoofStyle_Flat    0.037540\n",
      "236      KitchenQual_TA    0.030004\n",
      "..                  ...         ...\n",
      "187     BsmtQual_NoBsmt    0.000000\n",
      "182    Foundation_Stone    0.000000\n",
      "176        ExterCond_Po    0.000000\n",
      "173        ExterCond_Ex    0.000000\n",
      "153  Exterior2nd_CBlock    0.000000\n",
      "\n",
      "[306 rows x 2 columns]\n",
      "Cross-Validation Scores: [0.91632931 0.89078181 0.92374491 0.90638007 0.88678908] \n",
      "\n",
      "Mean R^2: 0.9048050348428582 \n",
      "\n",
      "Standard Deviation R^2: 0.014249445891612497\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for frame in ourFrames:\n",
    "    #the features will be X (independent variables)\n",
    "    X = frame.drop('SalePrice', axis=1)\n",
    "    X_array = X.values\n",
    "    #the target (dependent variable) will be y\n",
    "    y = frame['SalePrice']\n",
    "    y_array = y.values\n",
    "\n",
    "    #Split your training and testing sets of data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create a XGBoost Model\n",
    "    xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "    # Train the model on the training set\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    xgb_model_y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "    # Evaluate the Random Forest model\n",
    "    xgb_model_r2 = r2_score(y_test, xgb_model_y_pred)\n",
    "    print(f'R-squared on the test set: {xgb_model_r2}')\n",
    "\n",
    "    xgb_model_mse = mean_squared_error(y_test, xgb_model_y_pred)\n",
    "    print(f'Mean Squared Error on the test set: {xgb_model_mse}')\n",
    "\n",
    "    # Root Mean Squared Error (RMSE) on the test set\n",
    "    xgb_model_rmse = mean_squared_error(y_test, xgb_model_y_pred, squared=False)\n",
    "    print(\"Root Mean Squared Error (RMSE) on the test set:\", xgb_model_rmse)\n",
    "\n",
    "    # Display feature importances\n",
    "    feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': xgb_model.feature_importances_})\n",
    "    feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "    print('\\nFeature Importances:')\n",
    "    print(feature_importances)\n",
    "    \n",
    "    \n",
    "    # Create a KFold object\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(xgb_model, X, y, cv=kf, scoring='r2')\n",
    "    # You can replace 'r2' with other scoring metrics like 'neg_mean_squared_error', etc.\n",
    "\n",
    "    # Display the cross-validation scores\n",
    "    print(\"Cross-Validation Scores:\", cv_scores, '\\n')\n",
    "\n",
    "    # Print the mean and standard deviation of the scores\n",
    "    print(f\"Mean R^2: {cv_scores.mean()}\", '\\n')\n",
    "    print(f\"Standard Deviation R^2: {cv_scores.std()}\")\n",
    "    \n",
    "        \n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    \n",
    "    # feat_importances = pd.Series(rf_model.feature_importances_, index=X.columns)\n",
    "    # feat_importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "522aab62-9f76-4799-85f1-7221584a0a57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>TotalHouseSF</th>\n",
       "      <th>TotalBathroomCount</th>\n",
       "      <th>QualityOutdoorSF</th>\n",
       "      <th>YearAndRemodAvg</th>\n",
       "      <th>NonHouseSF</th>\n",
       "      <th>HighQualFinSF</th>\n",
       "      <th>HouseLotRatio</th>\n",
       "      <th>FrontageLotRatio</th>\n",
       "      <th>QualityOutdoorLotRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>909176150</td>\n",
       "      <td>856</td>\n",
       "      <td>126000</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1939</td>\n",
       "      <td>1950</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>238.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>618.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>856</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1712.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>166</td>\n",
       "      <td>1944.5</td>\n",
       "      <td>-6178.0</td>\n",
       "      <td>1712.0</td>\n",
       "      <td>21.698352</td>\n",
       "      <td>0.760456</td>\n",
       "      <td>2.103929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>905476230</td>\n",
       "      <td>1049</td>\n",
       "      <td>139500</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1984</td>\n",
       "      <td>1984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>149.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>552.0</td>\n",
       "      <td>2</td>\n",
       "      <td>393.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2098.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>105</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>-2137.0</td>\n",
       "      <td>2098.0</td>\n",
       "      <td>49.539551</td>\n",
       "      <td>0.991736</td>\n",
       "      <td>2.479339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>911128020</td>\n",
       "      <td>1001</td>\n",
       "      <td>124900</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6060</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1930</td>\n",
       "      <td>2007</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>737.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2007</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1838.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>282</td>\n",
       "      <td>1968.5</td>\n",
       "      <td>-4222.0</td>\n",
       "      <td>1838.0</td>\n",
       "      <td>30.330033</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>4.653465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>535377150</td>\n",
       "      <td>1039</td>\n",
       "      <td>114000</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8146</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1900</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>717</td>\n",
       "      <td>322</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>279</td>\n",
       "      <td>1951.5</td>\n",
       "      <td>-6702.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>17.726492</td>\n",
       "      <td>0.982077</td>\n",
       "      <td>3.424994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>534177230</td>\n",
       "      <td>1665</td>\n",
       "      <td>227000</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>8400</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2001</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>643.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>810</td>\n",
       "      <td>855</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2475.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>45</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>-5925.0</td>\n",
       "      <td>2475.0</td>\n",
       "      <td>29.464286</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PID  GrLivArea  SalePrice  MSSubClass  MSZoning  LotFrontage  \\\n",
       "0  909176150        856     126000          30         5         60.0   \n",
       "1  905476230       1049     139500         120         5         42.0   \n",
       "2  911128020       1001     124900          30         1         60.0   \n",
       "3  535377150       1039     114000          70         5         80.0   \n",
       "4  534177230       1665     227000          60         5         70.0   \n",
       "\n",
       "   LotArea  Street  Alley  LotShape  LandContour  Utilities  LotConfig  \\\n",
       "0     7890       1      1         3            3          0          0   \n",
       "1     4235       1      1         3            3          0          4   \n",
       "2     6060       1      1         3            3          0          4   \n",
       "3     8146       1      1         3            3          0          0   \n",
       "4     8400       1      1         3            3          0          4   \n",
       "\n",
       "   LandSlope  Neighborhood  Condition1  Condition2  BldgType  HouseStyle  \\\n",
       "0          0            19           2           2         0           2   \n",
       "1          0             7           2           2         4           2   \n",
       "2          0            10           2           2         0           2   \n",
       "3          0            18           2           2         0           5   \n",
       "4          0            15           2           2         0           5   \n",
       "\n",
       "   OverallQual  OverallCond  YearBuilt  YearRemodAdd  RoofStyle  RoofMatl  \\\n",
       "0            6            6       1939          1950          1         0   \n",
       "1            5            5       1984          1984          1         0   \n",
       "2            5            9       1930          2007          3         0   \n",
       "3            4            8       1900          2003          1         0   \n",
       "4            8            6       2001          2001          1         0   \n",
       "\n",
       "   Exterior1st  Exterior2nd  MasVnrType  MasVnrArea  ExterQual  ExterCond  \\\n",
       "0           13           14           2         0.0          3          3   \n",
       "1            6            6           1       149.0          4          3   \n",
       "2            8            8           2         0.0          4          3   \n",
       "3            8            8           2         0.0          4          4   \n",
       "4           12           13           2         0.0          4          3   \n",
       "\n",
       "   Foundation  BsmtQual  BsmtCond  BsmtExposure  BsmtFinType1  BsmtFinSF1  \\\n",
       "0           1         4         4             2             3       238.0   \n",
       "1           1         5         4             3             3       552.0   \n",
       "2           0         4         4             2             2       737.0   \n",
       "3           0         3         4             2             1         0.0   \n",
       "4           2         5         4             2             3       643.0   \n",
       "\n",
       "   BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  Heating  HeatingQC  \\\n",
       "0             1         0.0      618.0        856.0        1          3   \n",
       "1             2       393.0      104.0       1049.0        1          3   \n",
       "2             1         0.0      100.0        837.0        1          5   \n",
       "3             1         0.0      405.0        405.0        1          4   \n",
       "4             1         0.0      167.0        810.0        1          5   \n",
       "\n",
       "   CentralAir  Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  BsmtFullBath  \\\n",
       "0           1           3       856         0             0           1.0   \n",
       "1           1           3      1049         0             0           1.0   \n",
       "2           1           3      1001         0             0           0.0   \n",
       "3           1           3       717       322             0           0.0   \n",
       "4           1           3       810       855             0           1.0   \n",
       "\n",
       "   BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  KitchenAbvGr  KitchenQual  \\\n",
       "0           0.0         1         0             2             1            3   \n",
       "1           0.0         2         0             2             1            4   \n",
       "2           0.0         1         0             2             1            4   \n",
       "3           0.0         1         0             2             1            3   \n",
       "4           0.0         2         1             3             1            4   \n",
       "\n",
       "   TotRmsAbvGrd  Functional  Fireplaces  FireplaceQu  GarageType  GarageYrBlt  \\\n",
       "0             4           6           1            5           5       1939.0   \n",
       "1             5           6           0            1           1       1984.0   \n",
       "2             5           6           0            1           5       1930.0   \n",
       "3             6           6           0            1           5       1940.0   \n",
       "4             6           6           0            1           1       2001.0   \n",
       "\n",
       "   GarageFinish  GarageCars  GarageArea  GarageQual  GarageCond  PavedDrive  \\\n",
       "0             1         2.0       399.0           4           4           2   \n",
       "1             3         1.0       266.0           4           4           2   \n",
       "2             1         1.0       216.0           4           2           0   \n",
       "3             1         1.0       281.0           4           4           0   \n",
       "4             3         2.0       528.0           4           4           2   \n",
       "\n",
       "   WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  Fence  \\\n",
       "0           0            0              0          0          166      1   \n",
       "1           0          105              0          0            0      1   \n",
       "2         154            0             42         86            0      1   \n",
       "3           0            0            168          0          111      1   \n",
       "4           0           45              0          0            0      1   \n",
       "\n",
       "   MoSold  YrSold  SaleType  SaleCondition  TotalHouseSF  TotalBathroomCount  \\\n",
       "0       3    2010         9              4        1712.0                 2.0   \n",
       "1       2    2009         9              4        2098.0                 3.0   \n",
       "2      11    2007         9              4        1838.0                 1.0   \n",
       "3       5    2009         9              4        1444.0                 1.0   \n",
       "4      11    2009         9              4        2475.0                 3.5   \n",
       "\n",
       "   QualityOutdoorSF  YearAndRemodAvg  NonHouseSF  HighQualFinSF  \\\n",
       "0               166           1944.5     -6178.0         1712.0   \n",
       "1               105           1984.0     -2137.0         2098.0   \n",
       "2               282           1968.5     -4222.0         1838.0   \n",
       "3               279           1951.5     -6702.0         1444.0   \n",
       "4                45           2001.0     -5925.0         2475.0   \n",
       "\n",
       "   HouseLotRatio  FrontageLotRatio  QualityOutdoorLotRatio  \n",
       "0      21.698352          0.760456                2.103929  \n",
       "1      49.539551          0.991736                2.479339  \n",
       "2      30.330033          0.990099                4.653465  \n",
       "3      17.726492          0.982077                3.424994  \n",
       "4      29.464286          0.833333                0.535714  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_wOrdinal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f87181a1-3d85-463b-9b9a-87fb81656074",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared on the test set: 0.9166084147443928\n",
      "Mean Squared Error on the test set: 401859728.0576584\n",
      "Root Mean Squared Error (RMSE) on the test set: 20046.439286258756\n",
      "\n",
      "Feature Importances:\n",
      "          Feature  Importance\n",
      "81  HighQualFinSF    0.259688\n",
      "18    OverallQual    0.220354\n",
      "76   TotalHouseSF    0.169377\n",
      "53    KitchenQual    0.054261\n",
      "61     GarageCars    0.038327\n",
      "..            ...         ...\n",
      "46   LowQualFinSF    0.000143\n",
      "63     GarageQual    0.000079\n",
      "69      3SsnPorch    0.000018\n",
      "10      Utilities    0.000005\n",
      "15     Condition2    0.000000\n",
      "\n",
      "[85 rows x 2 columns]\n",
      "Cross-Validation Scores Rsquared: [0.91660841 0.90567262 0.91737334 0.92009667 0.87917199] \n",
      "\n",
      "Cross-Validation Scores RMSE: [20046.43928626 21224.54004189 19182.76138839 18887.19121856\n",
      " 21932.15439096] \n",
      "\n",
      "Mean R^2: 0.9077846041626992 \n",
      "\n",
      "Standard Deviation R^2: 0.01512965713463938 \n",
      "\n",
      "Mean RMSE: 20254.617265212193\n"
     ]
    }
   ],
   "source": [
    "#name the model for our scores tracker\n",
    "model_name = 'xgboost'\n",
    "    \n",
    "    #the features will be X (independent variables)\n",
    "X = train_wOrdinal.drop('SalePrice', axis=1)\n",
    "X_array = X.values\n",
    "#the target (dependent variable) will be y\n",
    "y = train_wOrdinal['SalePrice']\n",
    "y_array = y.values\n",
    "\n",
    "#Split your training and testing sets of data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a XGBoost Model\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "xgb_model_y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "xgb_model_r2 = r2_score(y_test, xgb_model_y_pred)\n",
    "print(f'R-squared on the test set: {xgb_model_r2}')\n",
    "\n",
    "xgb_model_mse = mean_squared_error(y_test, xgb_model_y_pred)\n",
    "print(f'Mean Squared Error on the test set: {xgb_model_mse}')\n",
    "\n",
    "# Root Mean Squared Error (RMSE) on the test set\n",
    "xgb_model_rmse = mean_squared_error(y_test, xgb_model_y_pred, squared=False)\n",
    "print(\"Root Mean Squared Error (RMSE) on the test set:\", xgb_model_rmse)\n",
    "\n",
    "# Display feature importances\n",
    "feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': xgb_model.feature_importances_})\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "print('\\nFeature Importances:')\n",
    "print(feature_importances)\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(xgb_model, X, y, cv=kf, scoring='r2')\n",
    "# You can replace 'r2' with other scoring metrics like 'neg_mean_squared_error', etc.\n",
    "\n",
    "def rmse_scorer(y_true, y_pred):\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        return rmse\n",
    "    \n",
    "    \n",
    "# Define the scoring function using neg_mean_squared_error\n",
    "scorer = make_scorer(rmse_scorer)\n",
    "# Use cross_val_score with the defined scorer\n",
    "rmse_scores = cross_val_score(xgb_model, X, y, cv=kf, scoring=scorer)\n",
    "\n",
    "\n",
    "\n",
    "# Display the cross-validation scores\n",
    "print(\"Cross-Validation Scores Rsquared:\", cv_scores, '\\n')\n",
    "print(\"Cross-Validation Scores RMSE:\", rmse_scores, '\\n')\n",
    "\n",
    "# Print the mean and standard deviation of the scores\n",
    "print(f\"Mean R^2: {cv_scores.mean()}\", '\\n')\n",
    "print(f\"Standard Deviation R^2: {cv_scores.std()}\", '\\n')\n",
    "print(f\"Mean RMSE: {rmse_scores.mean()}\")\n",
    "\n",
    "record = {'Model': model_name, 'r2_5kf_mean': cv_scores.mean(), 'rmse_5kf_mean': rmse_scores.mean()}\n",
    "masterScores = masterScores.append(record, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b811b9f9-b7a8-47f8-aa23-c0eb3d8dff40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>r2_5kf_mean</th>\n",
       "      <th>rmse_5kf_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.907785</td>\n",
       "      <td>20254.617265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  r2_5kf_mean  rmse_5kf_mean\n",
       "0  xgboost     0.907785   20254.617265"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterScores #want to use the sci kit and catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d907f91c-be68-40d1-8649-14da9b0311eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported to 'masterScores_xgboost.csv' in the same working directory.\n"
     ]
    }
   ],
   "source": [
    "output_file = 'masterScores_xgboost.csv'\n",
    "\n",
    "masterScores.to_csv(output_file, index=False, mode='w')\n",
    "\n",
    "print(f\"DataFrame exported to '{output_file}' in the same working directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "aeb5e316-4858-4089-8841-949dba2555a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "    max_depth = trial.suggest_int('max_depth', 10, 50)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 32)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 32)\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators = n_estimators, \n",
    "                                  max_depth = max_depth, \n",
    "                                  min_samples_split = min_samples_split, \n",
    "                                  min_samples_leaf = min_samples_leaf)\n",
    "    \n",
    "    score = cross_val_score(model, X_train, y_train, cv = 5, scoring = 'neg_mean_squared_error', n_jobs = -1).mean()\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "53b13e1f-0429-4079-bb2e-8039fd316c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction = 'maximize', sampler = optuna.samplers.RandomSampler(seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2a746a7b-9a2e-4958-a953-a6b692f4ed42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# study.optimize(objective, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "98683db0-076c-46a1-acfa-e4c285453fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4df19b4b-89d4-40b4-9458-841a8b0cdbc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4866e69d-f1f9-481f-934a-0560e1dd9af2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0966a25e-0ccb-4a4f-883f-0af9a069f657",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d94fc0b1-ccf3-4ccd-ac38-f9fcaa3e3ac5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optuna.visualization.plot_slice(study,params=['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cd37424c-ff01-496c-9c77-e367855f7dd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9fd829fc-26b9-48ba-adfb-b037df76a279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# best_n_estimators = best_params['n_estimators']\n",
    "# best_max_depth = best_params['max_depth']\n",
    "# best_min_samples_split = best_params['min_samples_split']\n",
    "# best_min_samples_leaf = best_params['min_samples_leaf']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ea9fdd4c-751e-43d5-846c-8ebd2950b9a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# best_model = RandomForestRegressor(n_estimators=best_n_estimators,\n",
    "#                                    max_depth=best_max_depth,\n",
    "#                                    min_samples_split=best_min_samples_split,\n",
    "#                                    min_samples_leaf=best_min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "69fe6f52-85b1-4a5d-92ae-7da56bc799f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# best_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "767911a0-7d88-43dd-ac14-761fef100e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "97464381-5973-4986-8afe-dabb449a5736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mean_squared_error(y_test, y_pred, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "179954bd-f792-453e-ac1b-678a6c7058e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "15a19d67-6536-4367-80a0-07890a0ecbc5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-27 23:25:01,636] A new study created in memory with name: no-name-dd955d84-33ed-424d-b130-52ff970a9efd\n",
      "/Users/briandrewes/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [23:25:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-01-27 23:25:01,898] Trial 0 finished with value: 589462159.4517553 and parameters: {'booster': 'gblinear', 'max_depth': 3, 'learning_rate': 0.17222889063290578, 'n_estimators': 200}. Best is trial 0 with value: 589462159.4517553.\n",
      "[I 2024-01-27 23:28:21,454] Trial 1 finished with value: 400068176.9137486 and parameters: {'booster': 'dart', 'max_depth': 8, 'learning_rate': 0.030629351403502352, 'n_estimators': 1000}. Best is trial 1 with value: 400068176.9137486.\n",
      "[I 2024-01-27 23:28:21,776] Trial 2 finished with value: 383047184.1084883 and parameters: {'booster': 'gbtree', 'max_depth': 5, 'learning_rate': 0.24729723315071214, 'n_estimators': 300}. Best is trial 2 with value: 383047184.1084883.\n",
      "[I 2024-01-27 23:28:39,304] Trial 3 finished with value: 353066788.6799589 and parameters: {'booster': 'dart', 'max_depth': 5, 'learning_rate': 0.18844653970944944, 'n_estimators': 300}. Best is trial 3 with value: 353066788.6799589.\n",
      "[I 2024-01-27 23:31:17,360] Trial 4 finished with value: 438981470.284968 and parameters: {'booster': 'dart', 'max_depth': 9, 'learning_rate': 0.17369138464766345, 'n_estimators': 900}. Best is trial 3 with value: 353066788.6799589.\n",
      "[I 2024-01-27 23:34:35,494] Trial 5 finished with value: 422448458.0376029 and parameters: {'booster': 'dart', 'max_depth': 9, 'learning_rate': 0.0684120843561069, 'n_estimators': 1000}. Best is trial 3 with value: 353066788.6799589.\n",
      "[I 2024-01-27 23:34:37,308] Trial 6 finished with value: 448914806.85855997 and parameters: {'booster': 'gbtree', 'max_depth': 10, 'learning_rate': 0.053850398306970894, 'n_estimators': 400}. Best is trial 3 with value: 353066788.6799589.\n",
      "/Users/briandrewes/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [23:34:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-01-27 23:34:37,615] Trial 7 finished with value: 552851613.3848265 and parameters: {'booster': 'gblinear', 'max_depth': 10, 'learning_rate': 0.06537398372888853, 'n_estimators': 800}. Best is trial 3 with value: 353066788.6799589.\n",
      "/Users/briandrewes/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [23:34:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-01-27 23:34:37,701] Trial 8 finished with value: 547387858.1638775 and parameters: {'booster': 'gblinear', 'max_depth': 8, 'learning_rate': 0.2885097471788269, 'n_estimators': 200}. Best is trial 3 with value: 353066788.6799589.\n",
      "/Users/briandrewes/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [23:34:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-01-27 23:34:38,066] Trial 9 finished with value: 496362623.8093865 and parameters: {'booster': 'gblinear', 'max_depth': 3, 'learning_rate': 0.2726578070734401, 'n_estimators': 900}. Best is trial 3 with value: 353066788.6799589.\n",
      "[I 2024-01-27 23:35:47,302] Trial 10 finished with value: 353634741.7080274 and parameters: {'booster': 'dart', 'max_depth': 5, 'learning_rate': 0.12163679312999315, 'n_estimators': 600}. Best is trial 3 with value: 353066788.6799589.\n",
      "[I 2024-01-27 23:36:56,318] Trial 11 finished with value: 346346535.08964837 and parameters: {'booster': 'dart', 'max_depth': 5, 'learning_rate': 0.12216156236124809, 'n_estimators': 600}. Best is trial 11 with value: 346346535.08964837.\n",
      "[I 2024-01-27 23:37:44,669] Trial 12 finished with value: 341733608.01543915 and parameters: {'booster': 'dart', 'max_depth': 5, 'learning_rate': 0.22108995921696153, 'n_estimators': 500}. Best is trial 12 with value: 341733608.01543915.\n",
      "[I 2024-01-27 23:40:12,794] Trial 13 finished with value: 372872742.0808803 and parameters: {'booster': 'dart', 'max_depth': 6, 'learning_rate': 0.2168483519576978, 'n_estimators': 600}. Best is trial 12 with value: 341733608.01543915.\n",
      "[I 2024-01-27 23:41:24,623] Trial 14 finished with value: 312358109.5649132 and parameters: {'booster': 'dart', 'max_depth': 4, 'learning_rate': 0.12664735154538276, 'n_estimators': 500}. Best is trial 14 with value: 312358109.5649132.\n",
      "[I 2024-01-27 23:42:34,173] Trial 15 finished with value: 309589412.5408393 and parameters: {'booster': 'dart', 'max_depth': 4, 'learning_rate': 0.1259132136351404, 'n_estimators': 500}. Best is trial 15 with value: 309589412.5408393.\n",
      "[I 2024-01-27 23:42:34,639] Trial 16 finished with value: 313219145.6366497 and parameters: {'booster': 'gbtree', 'max_depth': 4, 'learning_rate': 0.11487719537160986, 'n_estimators': 700}. Best is trial 15 with value: 309589412.5408393.\n",
      "[I 2024-01-27 23:43:13,450] Trial 17 finished with value: 313587968.24142927 and parameters: {'booster': 'dart', 'max_depth': 4, 'learning_rate': 0.09366395756752934, 'n_estimators': 400}. Best is trial 15 with value: 309589412.5408393.\n",
      "[I 2024-01-27 23:44:04,607] Trial 18 finished with value: 381760781.94571525 and parameters: {'booster': 'dart', 'max_depth': 7, 'learning_rate': 0.1485134815414119, 'n_estimators': 500}. Best is trial 15 with value: 309589412.5408393.\n",
      "[I 2024-01-27 23:44:05,075] Trial 19 finished with value: 311666937.24887115 and parameters: {'booster': 'gbtree', 'max_depth': 4, 'learning_rate': 0.15315331843366137, 'n_estimators': 700}. Best is trial 15 with value: 309589412.5408393.\n",
      "[I 2024-01-27 23:44:06,409] Trial 20 finished with value: 343934361.29969954 and parameters: {'booster': 'gbtree', 'max_depth': 6, 'learning_rate': 0.012952510075453602, 'n_estimators': 800}. Best is trial 15 with value: 309589412.5408393.\n",
      "[I 2024-01-27 23:44:06,906] Trial 21 finished with value: 310626285.25414777 and parameters: {'booster': 'gbtree', 'max_depth': 4, 'learning_rate': 0.14447761526876124, 'n_estimators': 700}. Best is trial 15 with value: 309589412.5408393.\n",
      "[I 2024-01-27 23:44:07,246] Trial 22 finished with value: 294097618.950592 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.1533607541979067, 'n_estimators': 700}. Best is trial 22 with value: 294097618.950592.\n",
      "[I 2024-01-27 23:44:07,587] Trial 23 finished with value: 283732833.60538346 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.09602485395931762, 'n_estimators': 700}. Best is trial 23 with value: 283732833.60538346.\n",
      "[I 2024-01-27 23:44:07,969] Trial 24 finished with value: 296834399.8248769 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.09736747846413227, 'n_estimators': 800}. Best is trial 23 with value: 283732833.60538346.\n",
      "[I 2024-01-27 23:44:08,377] Trial 25 finished with value: 284623954.5321272 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.0902795543154739, 'n_estimators': 800}. Best is trial 23 with value: 283732833.60538346.\n",
      "[I 2024-01-27 23:44:08,801] Trial 26 finished with value: 306031882.402786 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.08898719212288544, 'n_estimators': 900}. Best is trial 23 with value: 283732833.60538346.\n",
      "[I 2024-01-27 23:44:09,127] Trial 27 finished with value: 289732186.4117617 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.03897917149425263, 'n_estimators': 700}. Best is trial 23 with value: 283732833.60538346.\n",
      "[I 2024-01-27 23:44:09,523] Trial 28 finished with value: 286575394.73548794 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.03829839589064339, 'n_estimators': 800}. Best is trial 23 with value: 283732833.60538346.\n",
      "[I 2024-01-27 23:44:09,910] Trial 29 finished with value: 333264503.1180392 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.011723338443572835, 'n_estimators': 800}. Best is trial 23 with value: 283732833.60538346.\n",
      "[I 2024-01-27 23:44:11,347] Trial 30 finished with value: 356452034.7138697 and parameters: {'booster': 'gbtree', 'max_depth': 6, 'learning_rate': 0.07169137565074249, 'n_estimators': 900}. Best is trial 23 with value: 283732833.60538346.\n",
      "[I 2024-01-27 23:44:11,692] Trial 31 finished with value: 289266799.40656936 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.039223654680729074, 'n_estimators': 700}. Best is trial 23 with value: 283732833.60538346.\n",
      "[I 2024-01-27 23:44:12,075] Trial 32 finished with value: 283982525.53668094 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.03697339810907957, 'n_estimators': 800}. Best is trial 23 with value: 283732833.60538346.\n",
      "[I 2024-01-27 23:44:12,728] Trial 33 finished with value: 303130107.9506744 and parameters: {'booster': 'gbtree', 'max_depth': 4, 'learning_rate': 0.033847430259026895, 'n_estimators': 1000}. Best is trial 23 with value: 283732833.60538346.\n",
      "[I 2024-01-27 23:44:13,093] Trial 34 finished with value: 303369145.67399883 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.08474109404936846, 'n_estimators': 800}. Best is trial 23 with value: 283732833.60538346.\n",
      "[I 2024-01-27 23:44:13,543] Trial 35 finished with value: 285658632.5505843 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.052133764266039315, 'n_estimators': 900}. Best is trial 23 with value: 283732833.60538346.\n",
      "[I 2024-01-27 23:44:14,182] Trial 36 finished with value: 301744587.51114947 and parameters: {'booster': 'gbtree', 'max_depth': 4, 'learning_rate': 0.05429061468034643, 'n_estimators': 1000}. Best is trial 23 with value: 283732833.60538346.\n",
      "/Users/briandrewes/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [23:44:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-01-27 23:44:14,528] Trial 37 finished with value: 559088467.5963602 and parameters: {'booster': 'gblinear', 'max_depth': 7, 'learning_rate': 0.05405491905648298, 'n_estimators': 900}. Best is trial 23 with value: 283732833.60538346.\n",
      "[I 2024-01-27 23:44:14,647] Trial 38 finished with value: 356686120.75008076 and parameters: {'booster': 'gbtree', 'max_depth': 5, 'learning_rate': 0.10394234168835452, 'n_estimators': 100}. Best is trial 23 with value: 283732833.60538346.\n",
      "[I 2024-01-27 23:44:15,089] Trial 39 finished with value: 291180188.7736802 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.0687852215267232, 'n_estimators': 900}. Best is trial 23 with value: 283732833.60538346.\n",
      "/Users/briandrewes/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [23:44:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-01-27 23:44:15,467] Trial 40 finished with value: 502421663.8039728 and parameters: {'booster': 'gblinear', 'max_depth': 4, 'learning_rate': 0.1738688907392663, 'n_estimators': 1000}. Best is trial 23 with value: 283732833.60538346.\n",
      "[I 2024-01-27 23:44:15,831] Trial 41 finished with value: 293510359.2037801 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.02538964960086368, 'n_estimators': 800}. Best is trial 23 with value: 283732833.60538346.\n",
      "[I 2024-01-27 23:44:16,215] Trial 42 finished with value: 296133806.5723588 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.07605533013082404, 'n_estimators': 800}. Best is trial 23 with value: 283732833.60538346.\n",
      "[I 2024-01-27 23:44:16,634] Trial 43 finished with value: 280536845.9474988 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.05155610238272985, 'n_estimators': 900}. Best is trial 43 with value: 280536845.9474988.\n",
      "[I 2024-01-27 23:44:19,901] Trial 44 finished with value: 426128365.5211491 and parameters: {'booster': 'gbtree', 'max_depth': 9, 'learning_rate': 0.05321649834227685, 'n_estimators': 900}. Best is trial 43 with value: 280536845.9474988.\n",
      "[I 2024-01-27 23:44:20,840] Trial 45 finished with value: 342806255.61733884 and parameters: {'booster': 'gbtree', 'max_depth': 5, 'learning_rate': 0.10650686786077057, 'n_estimators': 1000}. Best is trial 43 with value: 280536845.9474988.\n",
      "[I 2024-01-27 23:44:21,472] Trial 46 finished with value: 299112649.42415816 and parameters: {'booster': 'gbtree', 'max_depth': 4, 'learning_rate': 0.05831806884655884, 'n_estimators': 900}. Best is trial 43 with value: 280536845.9474988.\n",
      "/Users/briandrewes/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [23:44:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-01-27 23:44:21,705] Trial 47 finished with value: 560558376.061086 and parameters: {'booster': 'gblinear', 'max_depth': 3, 'learning_rate': 0.07965141828604143, 'n_estimators': 600}. Best is trial 43 with value: 280536845.9474988.\n",
      "[I 2024-01-27 23:44:22,126] Trial 48 finished with value: 295017452.406576 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.024783382239168247, 'n_estimators': 900}. Best is trial 43 with value: 280536845.9474988.\n",
      "[I 2024-01-27 23:44:22,773] Trial 49 finished with value: 306052813.2250122 and parameters: {'booster': 'gbtree', 'max_depth': 4, 'learning_rate': 0.04234946420898976, 'n_estimators': 1000}. Best is trial 43 with value: 280536845.9474988.\n",
      "[I 2024-01-27 23:44:23,528] Trial 50 finished with value: 346914877.56107277 and parameters: {'booster': 'gbtree', 'max_depth': 5, 'learning_rate': 0.13349955003892422, 'n_estimators': 800}. Best is trial 43 with value: 280536845.9474988.\n",
      "[I 2024-01-27 23:44:23,905] Trial 51 finished with value: 303062729.30201185 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.021600821840043534, 'n_estimators': 800}. Best is trial 43 with value: 280536845.9474988.\n",
      "[I 2024-01-27 23:44:24,245] Trial 52 finished with value: 287958672.9175765 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.06715237058520122, 'n_estimators': 700}. Best is trial 43 with value: 280536845.9474988.\n",
      "[I 2024-01-27 23:44:24,765] Trial 53 finished with value: 304190409.1633689 and parameters: {'booster': 'gbtree', 'max_depth': 4, 'learning_rate': 0.04410661695992655, 'n_estimators': 800}. Best is trial 43 with value: 280536845.9474988.\n",
      "[I 2024-01-27 23:44:25,197] Trial 54 finished with value: 286859219.0282306 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.04404581746217024, 'n_estimators': 900}. Best is trial 43 with value: 280536845.9474988.\n",
      "/Users/briandrewes/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [23:44:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-01-27 23:44:25,477] Trial 55 finished with value: 566968513.8731382 and parameters: {'booster': 'gblinear', 'max_depth': 4, 'learning_rate': 0.06345252299448187, 'n_estimators': 700}. Best is trial 43 with value: 280536845.9474988.\n",
      "[I 2024-01-27 23:44:25,854] Trial 56 finished with value: 290111306.39438707 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.027921471135619196, 'n_estimators': 800}. Best is trial 43 with value: 280536845.9474988.\n",
      "[I 2024-01-27 23:44:27,617] Trial 57 finished with value: 415837451.5076218 and parameters: {'booster': 'gbtree', 'max_depth': 8, 'learning_rate': 0.08873074418859526, 'n_estimators': 600}. Best is trial 43 with value: 280536845.9474988.\n",
      "[I 2024-01-27 23:44:28,204] Trial 58 finished with value: 328147544.73291504 and parameters: {'booster': 'gbtree', 'max_depth': 4, 'learning_rate': 0.19049939633991586, 'n_estimators': 900}. Best is trial 43 with value: 280536845.9474988.\n",
      "[I 2024-01-27 23:44:30,898] Trial 59 finished with value: 458804560.0307627 and parameters: {'booster': 'gbtree', 'max_depth': 10, 'learning_rate': 0.11369707232941671, 'n_estimators': 600}. Best is trial 43 with value: 280536845.9474988.\n",
      "[I 2024-01-27 23:46:07,285] Trial 60 finished with value: 290462808.6901201 and parameters: {'booster': 'dart', 'max_depth': 3, 'learning_rate': 0.08022678311887133, 'n_estimators': 700}. Best is trial 43 with value: 280536845.9474988.\n",
      "[I 2024-01-27 23:46:07,710] Trial 61 finished with value: 284952345.57759774 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.04746043546705178, 'n_estimators': 900}. Best is trial 43 with value: 280536845.9474988.\n",
      "[I 2024-01-27 23:46:08,175] Trial 62 finished with value: 291421238.6989463 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.048124695675543394, 'n_estimators': 900}. Best is trial 43 with value: 280536845.9474988.\n",
      "[I 2024-01-27 23:46:08,543] Trial 63 finished with value: 305579804.65688974 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.02048612725002538, 'n_estimators': 800}. Best is trial 43 with value: 280536845.9474988.\n",
      "[I 2024-01-27 23:46:09,211] Trial 64 finished with value: 312103216.90960443 and parameters: {'booster': 'gbtree', 'max_depth': 4, 'learning_rate': 0.011121970554158322, 'n_estimators': 1000}. Best is trial 43 with value: 280536845.9474988.\n",
      "[I 2024-01-27 23:46:09,578] Trial 65 finished with value: 278942955.9733671 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.05877416414792031, 'n_estimators': 800}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:46:09,993] Trial 66 finished with value: 300593424.22437215 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.0999889010949136, 'n_estimators': 900}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:46:10,192] Trial 67 finished with value: 291223557.63706714 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.06036350851570758, 'n_estimators': 400}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:46:10,727] Trial 68 finished with value: 358953559.7538491 and parameters: {'booster': 'gbtree', 'max_depth': 4, 'learning_rate': 0.2515397804294327, 'n_estimators': 800}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:47:44,197] Trial 69 finished with value: 305929543.935877 and parameters: {'booster': 'dart', 'max_depth': 4, 'learning_rate': 0.07360752491478298, 'n_estimators': 700}. Best is trial 65 with value: 278942955.9733671.\n",
      "/Users/briandrewes/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [23:47:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-01-27 23:47:44,554] Trial 70 finished with value: 609682177.1150072 and parameters: {'booster': 'gblinear', 'max_depth': 3, 'learning_rate': 0.03263831332352118, 'n_estimators': 900}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:47:44,918] Trial 71 finished with value: 287923144.4618152 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.03570376735549061, 'n_estimators': 800}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:47:45,290] Trial 72 finished with value: 290727047.1550961 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.05088009239736806, 'n_estimators': 800}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:47:45,616] Trial 73 finished with value: 294918353.6227711 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.061807657700446855, 'n_estimators': 700}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:47:46,057] Trial 74 finished with value: 288808849.3782936 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.09226575709287568, 'n_estimators': 900}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:47:46,443] Trial 75 finished with value: 308723025.52903885 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.018431556829763857, 'n_estimators': 800}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:47:47,029] Trial 76 finished with value: 297016959.6984761 and parameters: {'booster': 'gbtree', 'max_depth': 4, 'learning_rate': 0.0359589841858182, 'n_estimators': 900}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:47:47,353] Trial 77 finished with value: 290869630.59726864 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.046524453190295044, 'n_estimators': 700}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:47:47,920] Trial 78 finished with value: 314459610.64173216 and parameters: {'booster': 'gbtree', 'max_depth': 4, 'learning_rate': 0.08092942847959035, 'n_estimators': 800}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:47:48,413] Trial 79 finished with value: 286832415.3640895 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.06949493162905718, 'n_estimators': 1000}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:47:50,134] Trial 80 finished with value: 374958023.622351 and parameters: {'booster': 'gbtree', 'max_depth': 7, 'learning_rate': 0.05701703280475814, 'n_estimators': 900}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:47:50,593] Trial 81 finished with value: 284148459.7143972 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.07134535982530602, 'n_estimators': 1000}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:47:51,115] Trial 82 finished with value: 290893713.88658273 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.11209812510019666, 'n_estimators': 1000}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:47:51,584] Trial 83 finished with value: 285403639.2126891 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.031456365753500706, 'n_estimators': 1000}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:47:52,054] Trial 84 finished with value: 286066768.2772702 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.03137784544807752, 'n_estimators': 1000}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:47:52,521] Trial 85 finished with value: 299216052.29678684 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.0875857743043148, 'n_estimators': 1000}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:51:03,359] Trial 86 finished with value: 307145015.4251071 and parameters: {'booster': 'dart', 'max_depth': 4, 'learning_rate': 0.13543392500068227, 'n_estimators': 1000}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:51:03,832] Trial 87 finished with value: 292102329.89060354 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.07346976247453502, 'n_estimators': 1000}. Best is trial 65 with value: 278942955.9733671.\n",
      "/Users/briandrewes/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [23:51:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-01-27 23:51:04,244] Trial 88 finished with value: 564006276.1232022 and parameters: {'booster': 'gblinear', 'max_depth': 3, 'learning_rate': 0.051017403129724685, 'n_estimators': 900}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:51:05,425] Trial 89 finished with value: 309980657.3285739 and parameters: {'booster': 'gbtree', 'max_depth': 4, 'learning_rate': 0.0396821009361172, 'n_estimators': 1000}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:51:05,918] Trial 90 finished with value: 285224133.8440665 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.0653084678077568, 'n_estimators': 900}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:51:06,359] Trial 91 finished with value: 294844577.2710158 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.06548382046160768, 'n_estimators': 900}. Best is trial 65 with value: 278942955.9733671.\n",
      "[I 2024-01-27 23:51:06,813] Trial 92 finished with value: 278439961.9268593 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.056842782261922145, 'n_estimators': 900}. Best is trial 92 with value: 278439961.9268593.\n",
      "[I 2024-01-27 23:51:07,373] Trial 93 finished with value: 296011380.49483865 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.09606864835483105, 'n_estimators': 900}. Best is trial 92 with value: 278439961.9268593.\n",
      "[I 2024-01-27 23:51:07,911] Trial 94 finished with value: 293417704.12358016 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.05944023266831687, 'n_estimators': 900}. Best is trial 92 with value: 278439961.9268593.\n",
      "[I 2024-01-27 23:51:08,432] Trial 95 finished with value: 301988519.8985519 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.08358699515244526, 'n_estimators': 1000}. Best is trial 92 with value: 278439961.9268593.\n",
      "[I 2024-01-27 23:51:08,875] Trial 96 finished with value: 307098972.6359348 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.07704419685317643, 'n_estimators': 900}. Best is trial 92 with value: 278439961.9268593.\n",
      "[I 2024-01-27 23:51:11,103] Trial 97 finished with value: 439423382.14174044 and parameters: {'booster': 'gbtree', 'max_depth': 9, 'learning_rate': 0.16645406485675546, 'n_estimators': 800}. Best is trial 92 with value: 278439961.9268593.\n",
      "[I 2024-01-27 23:51:11,755] Trial 98 finished with value: 303879692.65651256 and parameters: {'booster': 'gbtree', 'max_depth': 4, 'learning_rate': 0.04579756535737021, 'n_estimators': 1000}. Best is trial 92 with value: 278439961.9268593.\n",
      "[I 2024-01-27 23:51:11,920] Trial 99 finished with value: 344156860.2884918 and parameters: {'booster': 'gbtree', 'max_depth': 3, 'learning_rate': 0.027273998854690104, 'n_estimators': 300}. Best is trial 92 with value: 278439961.9268593.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.056842782261922145,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=900, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.056842782261922145,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=900, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.056842782261922145,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=900, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart']),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBRegressor(**params, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    return mse\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "#study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_model = xgb.XGBRegressor(**best_params, random_state=42)\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e442e8a7-3bc8-4ec6-a76b-b305d618c7a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booster': 'gbtree',\n",
       " 'max_depth': 3,\n",
       " 'learning_rate': 0.056842782261922145,\n",
       " 'n_estimators': 900}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "71d8b19e-0e9e-4c77-9133-7e0a450d7c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.056842782261922145,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=900, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.056842782261922145,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=900, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.056842782261922145,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=900, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fa3b4c52-2d91-4b3e-b8e9-dbb16d84318c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9a8b7742-1bc9-4e4e-b239-5832e8a6bb80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared on the test set: 0.9422197642550034\n",
      "Mean Squared Error on the test set: 278439961.9268593\n",
      "Cross-Validation Scores Rsquared: [0.93809358 0.92175837 0.93926221 0.92720627 0.88940537] \n",
      "\n",
      "Mean R^2: 0.9231451592777111 \n",
      "\n",
      "Standard Deviation R^2: 0.018110792801501782 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#the features will be X (independent variables)\n",
    "X = frame.drop('SalePrice', axis=1)\n",
    "X_array = X.values\n",
    "#the target (dependent variable) will be y\n",
    "y = frame['SalePrice']\n",
    "y_array = y.values\n",
    "\n",
    "#Split your training and testing sets of data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "best_r2 = r2_score(y_test, best_pred)\n",
    "print(f'R-squared on the test set: {best_r2}')\n",
    "\n",
    "best_model_mse = mean_squared_error(y_test, best_pred)\n",
    "print(f'Mean Squared Error on the test set: {best_model_mse}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=kf, scoring='r2')\n",
    "# You can replace 'r2' with other scoring metrics like 'neg_mean_squared_error', etc.\n",
    "\n",
    "    \n",
    "\n",
    "# Use cross_val_score with the defined scorer\n",
    "rmse_scores = cross_val_score(best_model, X, y, cv=kf, scoring=scorer)\n",
    "\n",
    "\n",
    "\n",
    "# Display the cross-validation scores\n",
    "print(\"Cross-Validation Scores Rsquared:\", cv_scores, '\\n')\n",
    "\n",
    "\n",
    "# Print the mean and standard deviation of the scores\n",
    "print(f\"Mean R^2: {cv_scores.mean()}\", '\\n')\n",
    "print(f\"Standard Deviation R^2: {cv_scores.std()}\", '\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
